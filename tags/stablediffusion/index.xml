<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stablediffusion on 頑張らないために頑張る</title>
    <link>https://ysko909.github.io/tags/stablediffusion/</link>
    <description>Recent content in Stablediffusion on 頑張らないために頑張る</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>© Copyright ysko</copyright>
    <lastBuildDate>Mon, 05 Sep 2022 22:09:55 +0900</lastBuildDate>
    
	<atom:link href="https://ysko909.github.io/tags/stablediffusion/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stable Diffusionを使ってGoogle Colaboratory上でimg2imgして画像を生成する</title>
      <link>https://ysko909.github.io/posts/execute-stable-diffusion-on-google-colaboratory/</link>
      <pubDate>Mon, 05 Sep 2022 22:09:55 +0900</pubDate>
      
      <guid>https://ysko909.github.io/posts/execute-stable-diffusion-on-google-colaboratory/</guid>
      <description>概要 Stable Diffusion（以下、SD）とは、Midjourneyのように「テキストから画像を生成する」AIです。Midjourneyと異なるのはやっぱりなんといっても、そのAIモデルがまるっと公開されていることでしょうか。そのため、現状のモデルをそのまま使うことも可能ですし、オリジナルのモデルを作ることも可能です。そして、そのモデルを組み込んだwebアプリなんかを作ることも可能なわけです。
そんなわけで、今回はこれをGoogle Colaboratory（以下、Colab）で動作させて、とくにimg2img（元画像と文章から画像を生成する）をやってみたいのですよ。というわけで行ってみましょう。
注意 今回SDを利用して画像を生成するわけですが、あくまでも行うことは画像処理分野における機械学習の開発手法について探求することを目的としており、その結果生成された画像は個人利用の範囲内で扱うことを想定しています。生成した結果を見て「AIすげーなー」とか思って、どんな仕組みで生成されているのか、より精度を高めたい場合にどのような改善案が考えられるか。これらを探求するのが目的です。今回の記事はその探求の入り口でしかありません。
さすがに、Colabをバックエンドに使って商用サービスなんか作らないだろうけど、生成した結果をどっかで売りに出すとかそういうことは一切想定していませんし推奨もしません。また、当ページの処理はすべて自己責任で実施してください。この処理を実行したことで発生したトラブルなどについて、筆者は一切責任を負いません。
目的 今回の最終的なゴールは、「SDをColab上で動作させて、img2imgを利用して画像生成を実行してみて、その挙動を確認する」です。
「img2img」って何よ、って話ですがこれは「入力された画像とテキストから画像を生成すること」を指します。SDやMidjourneyが有名になったのは「テキストから画像を生成すること」の「text2img」の方ですが、それに入力としてガイドのための画像を追加したのがimg2imgと言えます。テキストだけで生成するのではなく、ラフ画をガイドとして渡すことで生成の精度を向上させようというわけです。人間同士の打ち合わせでは、簡単なスケッチを書いてアイデアの集約やすり合わせを行ったりしますが、まさにそれです。そのすり合わせを人間とAIでやろうというわけです。
もう1つの理由としては、テキストから画像生成するのも楽しいけど、入力の画像とテキストでどんな出力かましてくれるのよ？っていうところに興味があります。テキストだけよりは精度良いんでしょ？良いよね？良いと言ってくれ。
というわけで今回は、王道の「テキストから画像を生成する」ところをまるっとすっ飛ばしていきなりimg2imgもやってみます。っていうか、text2imgだったら、ほら、自分で環境を用意しなくてもできるし。
実行環境 SDはめちゃくちゃ優秀なので、エンドユーザーが買えるような端末（たとえばM1が搭載されているようなMac）でも動作するよう調整されています。そのため、高価なGPUを搭載していないような「そこそこのスペック」の端末であれば、ローカルで環境構築して動かせます・・・が、手持ちの端末が最近ちょっとストレージの容量少ないんですよねぇ。というわけで、Colabを利用しようぜ！というわけです。もちろん、SDはちゃんとColab上で動作してくれます。しかも、Colabの無料プランでもGPUが割り当てられればSDが実行できます。やったぜ。
あ、ちなみにですがGoogle Colaboratoryとは、ブラウザで利用できるPythonの環境です。GPUも利用できます。スゲェ、さすがGoogle。
手順 ざっくりした手順はこんな感じ。
 Hugging Faceアカウント登録 Hugging Faceのトークン発行 Colabの初期設定 Stable Diffusionの初期設定 入力画像の準備とpromptの作成 画像生成！お気に入りのものが生成されるまでひたすら生成！  手順自体がそもそも多くないうえに、コードもほぼコピペで動かせるので困ることはあまりないかもしれません。強いて言えば、後述する「prompt」が鬼門かな、というくらいです。例外は、SD側の仕様が変わるとかそういうシチュエーションですかね。そういう場合は、「そういうケースに陥ったら対応」っていうスタンスで行きます。
では行ってみましょう。
Hugging Faceアカウント登録 Stable Diffusionを利用するにはHugging Faceのアカウントを取得し、アクセストークンを発行する必要があります。
まず、Hugging Faceのwebページにアクセスして、右上の「Sign Up」をクリックします。
あるいはStable Diffusionのページにアクセスします。
ページ下部の「Access repository」をクリックします。すると、Hugging Faceのログイン画面が表示されるので、そこで「Sign Up」をクリックしてください。
メールアドレスと設定したいパスワードをクリックします。
今度はユーザー名などを入力します。必要に応じて、GitHubやTwitterのアカウントなどを登録できます。最後に「I have read and agree with the Terms of Service and the Code of Conduct」の部分をチェックして「Create Account」をクリックします。ちなみに、ユーザー名は早いもの勝ちのようです。自分が最初取ろうとしたユーザー名は「すでにあるぜ！」と言われて取得できませんでした。
なお、この時点でさっき入力したメールアドレス宛に認証メールが来ているはずです。到着していたら記載されているURLをクリックして、メールアドレスを認証します。
これでアカウント登録が完了しました。
Hugging Faceのトークン発行 この時点でHugging Faceにログインできているはずなので、Settings＞Access Tokenにアクセスします。Settingsは、画面右上の円形アイコンをクリックすると表示されるメニューの中にいます。</description>
    </item>
    
  </channel>
</rss>